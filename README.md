# ğŸ¤– Mini RAG Chatbot â€“ Local AI Assistant

> **An intelligent local assistant that answers questions from PDF documents using a Retrieval-Augmented Generation (RAG) architecture.**  
> Built with **LangChain**, **Ollama (Mistral)**, **ChromaDB**, and **Gradio**.

---

## ğŸ¯ Project Goal

CrÃ©er un **assistant intelligent local** capable de rÃ©pondre Ã  des questions en langage naturel Ã  partir dâ€™un document PDF.  
Le projet met en Å“uvre une architecture **Retrieval-Augmented Generation (RAG)** pour combiner **recherche sÃ©mantique** et **gÃ©nÃ©ration de texte**, garantissant des **rÃ©ponses prÃ©cises, pertinentes et contextuelles**.

---

## ğŸ§© Tech Stack

| Category | Tools / Frameworks |
|-----------|--------------------|
| **Langage** | Python |
| **Framework RAG** | LangChain |
| **LLM Local** | Ollama (Mistral) |
| **Vector Store** | ChromaDB |
| **Interface Web** | Gradio |
| **Conteneurisation** | Docker |
| **Embeddings** | nomic-embed-text |
| **Alternative Vector Store** | FAISS |

---

## ğŸ—ï¸ Architecture Overview

**Pipeline RAG complet :**

1. ğŸ“¥ Chargement et dÃ©coupage du PDF  
2. ğŸ§® GÃ©nÃ©ration dâ€™embeddings via *nomic-embed-text*  
3. ğŸ§  Stockage et recherche sÃ©mantique avec *ChromaDB*  
4. ğŸ’¬ GÃ©nÃ©ration de rÃ©ponses par *Mistral* (via Ollama)  
5. ğŸŒ Interface utilisateur simple et interactive avec *Gradio*  

```text
User Query â†’ PDF Splitter â†’ Embeddings â†’ Vector Store â†’ RAG Chain â†’ Answer
